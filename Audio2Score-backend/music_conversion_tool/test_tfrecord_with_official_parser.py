# test_tfrecord_with_official_parser.py
import tensorflow as tf
import numpy as np
import os

def test_official_parser():
    """ä½¿ç”¨ Basic Pitch å®˜æ–¹çš„ TFRecord è§£æå™¨æ¸¬è©¦"""
    
    print("=== ä½¿ç”¨ Basic Pitch å®˜æ–¹è§£æå™¨æ¸¬è©¦ ===")
    
    try:
        # ç›´æ¥å¾ tf_example_deserialization å°å…¥è§£æå‡½æ•¸
        # ç”±æ–¼æˆ‘å€‘å·²ç¶“æœ‰åŸå§‹ç¢¼ï¼Œå¯ä»¥ç›´æ¥å®šç¾©æˆ–å°å…¥
        
        print("1. å®šç¾©/å°å…¥è§£æå‡½æ•¸...")
        
        # å¾æä¾›çš„ä»£ç¢¼ä¸­è¤‡è£½ç›¸é—œå‡½æ•¸
        def parse_transcription_tfexample(serialized_example):
            """è§£æ TFRecord ç¤ºä¾‹ - å¾ tf_example_deserialization.py è¤‡è£½"""
            schema = {
                "file_id": tf.io.FixedLenFeature((), tf.string),
                "source": tf.io.FixedLenFeature((), tf.string),
                "audio_wav": tf.io.FixedLenFeature((), tf.string),
                "notes_indices": tf.io.FixedLenFeature((), tf.string),
                "notes_values": tf.io.FixedLenFeature((), tf.string),
                "onsets_indices": tf.io.FixedLenFeature((), tf.string),
                "onsets_values": tf.io.FixedLenFeature((), tf.string),
                "contours_indices": tf.io.FixedLenFeature((), tf.string),
                "contours_values": tf.io.FixedLenFeature((), tf.string),
                "notes_onsets_shape": tf.io.FixedLenFeature((), tf.string),
                "contours_shape": tf.io.FixedLenFeature((), tf.string),
            }
            example = tf.io.parse_single_example(serialized_example, schema)
            return (
                example["file_id"],
                example["source"],
                example["audio_wav"],
                tf.io.parse_tensor(example["notes_indices"], out_type=tf.int64),
                tf.io.parse_tensor(example["notes_values"], out_type=tf.float32),
                tf.io.parse_tensor(example["onsets_indices"], out_type=tf.int64),
                tf.io.parse_tensor(example["onsets_values"], out_type=tf.float32),
                tf.io.parse_tensor(example["contours_indices"], out_type=tf.int64),
                tf.io.parse_tensor(example["contours_values"], out_type=tf.float32),
                tf.io.parse_tensor(example["notes_onsets_shape"], out_type=tf.int64),
                tf.io.parse_tensor(example["contours_shape"], out_type=tf.int64),
            )
        
        def sparse2dense(values, indices, dense_shape):
            """å°‡ç¨€ç–å¼µé‡è½‰æ›ç‚ºå¯†é›†å¼µé‡"""
            if tf.rank(indices) != 2 and tf.size(indices) == 0:
                indices = tf.zeros([0, 1], dtype=indices.dtype)
            sp = tf.SparseTensor(indices=indices, values=values, dense_shape=dense_shape)
            return tf.sparse.to_dense(sp, validate_indices=False)
        
        print("âœ… è§£æå‡½æ•¸å®šç¾©å®Œæˆ")
        
        # æ‰¾åˆ° TFRecord æ–‡ä»¶
        print("\n2. å°‹æ‰¾ TFRecord æ–‡ä»¶...")
        tfrecord_files = []
        for root, dirs, files in os.walk("./output_tfrecord"):
            for file in files:
                if file.endswith('.tfrecord'):
                    tfrecord_files.append(os.path.join(root, file))
        
        print(f"æ‰¾åˆ° {len(tfrecord_files)} å€‹ TFRecord æ–‡ä»¶")
        
        if not tfrecord_files:
            print("âŒ æ²’æœ‰æ‰¾åˆ° TFRecord æ–‡ä»¶")
            return
        
        # æ¸¬è©¦ç¬¬ä¸€å€‹æ–‡ä»¶
        test_file = tfrecord_files[0]
        print(f"\n3. æ¸¬è©¦æ–‡ä»¶: {os.path.basename(test_file)}")
        
        # å‰µå»ºæ•¸æ“šé›†
        raw_dataset = tf.data.TFRecordDataset(test_file)
        
        # è§£ææ•¸æ“š
        parsed_dataset = raw_dataset.map(parse_transcription_tfexample)
        
        # æª¢æŸ¥ç¬¬ä¸€å€‹æ¨£æœ¬
        print("\n4. æª¢æŸ¥ç¬¬ä¸€å€‹æ¨£æœ¬:")
        for (
            file_id, source, audio_wav, 
            notes_indices, notes_values,
            onsets_indices, onsets_values,
            contours_indices, contours_values,
            notes_onsets_shape, contours_shape
        ) in parsed_dataset.take(1):
            
            print(f"   file_id: {file_id.numpy().decode('utf-8')}")
            print(f"   source: {source.numpy().decode('utf-8')}")
            
            # è§£ç¢¼éŸ³é »
            print("\n   è§£ç¢¼éŸ³é »...")
            audio_decoded = tf.audio.decode_wav(
                audio_wav,
                desired_channels=1,  # Basic Pitch ä½¿ç”¨å–®è²é“
                desired_samples=-1,
            )
            audio = audio_decoded.audio
            sample_rate = audio_decoded.sample_rate
            
            print(f"   éŸ³é »å½¢ç‹€: {audio.shape}")
            print(f"   æ¡æ¨£ç‡: {sample_rate}")
            print(f"   éŸ³é »ç¯„åœ: [{audio.numpy().min():.3f}, {audio.numpy().max():.3f}]")
            
            # è§£æè¨»é‡‹
            print("\n   è§£æè¨»é‡‹...")
            
            # è§£æ notes
            notes_dense = sparse2dense(notes_values, notes_indices, notes_onsets_shape)
            print(f"   notes å½¢ç‹€: {notes_dense.shape}")
            print(f"   notes éé›¶æ¯”ä¾‹: {np.mean(notes_dense.numpy() > 0):.2%}")
            
            # è§£æ onsets
            onsets_dense = sparse2dense(onsets_values, onsets_indices, notes_onsets_shape)
            print(f"   onsets å½¢ç‹€: {onsets_dense.shape}")
            print(f"   onsets éé›¶æ¯”ä¾‹: {np.mean(onsets_dense.numpy() > 0):.2%}")
            
            # è§£æ contours
            contours_dense = sparse2dense(contours_values, contours_indices, contours_shape)
            print(f"   contours å½¢ç‹€: {contours_dense.shape}")
            print(f"   contours éé›¶æ¯”ä¾‹: {np.mean(contours_dense.numpy() > 0):.2%}")
            
            # æª¢æŸ¥å½¢ç‹€æ˜¯å¦æ­£ç¢º
            print(f"\n   å½¢ç‹€æª¢æŸ¥:")
            print(f"   notes_onsets_shape: {notes_onsets_shape.numpy()}")
            print(f"   contours_shape: {contours_shape.numpy()}")
            
            return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_multiple_samples():
    """æ¸¬è©¦å¤šå€‹æ¨£æœ¬"""
    
    print("\n=== æ¸¬è©¦å¤šå€‹æ¨£æœ¬ ===")
    
    try:
        # ç°¡åŒ–çš„è§£æå‡½æ•¸
        def parse_tfrecord(serialized_example):
            schema = {
                "file_id": tf.io.FixedLenFeature((), tf.string),
                "source": tf.io.FixedLenFeature((), tf.string),
                "audio_wav": tf.io.FixedLenFeature((), tf.string),
                "notes_indices": tf.io.FixedLenFeature((), tf.string),
                "notes_values": tf.io.FixedLenFeature((), tf.string),
                "onsets_indices": tf.io.FixedLenFeature((), tf.string),
                "onsets_values": tf.io.FixedLenFeature((), tf.string),
                "contours_indices": tf.io.FixedLenFeature((), tf.string),
                "contours_values": tf.io.FixedLenFeature((), tf.string),
                "notes_onsets_shape": tf.io.FixedLenFeature((), tf.string),
                "contours_shape": tf.io.FixedLenFeature((), tf.string),
            }
            return tf.io.parse_single_example(serialized_example, schema)
        
        # æ‰¾åˆ°æ–‡ä»¶
        tfrecord_files = []
        for root, dirs, files in os.walk("./output_tfrecord"):
            for file in files:
                if file.endswith('.tfrecord'):
                    tfrecord_files.append(os.path.join(root, file))
                    if len(tfrecord_files) >= 3:  # åªå–3å€‹æ–‡ä»¶
                        break
            if len(tfrecord_files) >= 3:
                break
        
        print(f"æ¸¬è©¦ {len(tfrecord_files)} å€‹æ–‡ä»¶")
        
        all_stats = {
            'audio_lengths': [],
            'notes_density': [],
            'onsets_density': [],
            'contours_density': []
        }
        
        for i, file_path in enumerate(tfrecord_files):
            print(f"\n--- æ–‡ä»¶ {i+1}: {os.path.basename(file_path)} ---")
            
            dataset = tf.data.TFRecordDataset(file_path)
            parsed_dataset = dataset.map(parse_tfrecord)
            
            sample_count = 0
            for example in parsed_dataset.take(3):  # æ¯å€‹æ–‡ä»¶å–3å€‹æ¨£æœ¬
                sample_count += 1
                
                # è§£ç¢¼éŸ³é »
                audio_decoded = tf.audio.decode_wav(
                    example['audio_wav'],
                    desired_channels=1,
                    desired_samples=-1,
                )
                audio_length = audio_decoded.audio.shape[0]
                all_stats['audio_lengths'].append(audio_length)
                
                print(f"   æ¨£æœ¬ {sample_count}:")
                print(f"     éŸ³é »é•·åº¦: {audio_length} æ¡æ¨£é»")
                print(f"     æ–‡ä»¶ID: {example['file_id'].numpy().decode('utf-8')[:50]}...")
                
                # è§£æç¨€ç–å¼µé‡
                def parse_sparse_tensor(values_str, indices_str, shape_str):
                    values = tf.io.parse_tensor(values_str, out_type=tf.float32)
                    indices = tf.io.parse_tensor(indices_str, out_type=tf.int64)
                    shape = tf.io.parse_tensor(shape_str, out_type=tf.int64)
                    
                    if tf.size(indices) == 0:
                        return 0.0
                    
                    # è¨ˆç®—å¯†åº¦
                    total_elements = tf.reduce_prod(shape)
                    non_zero_count = tf.shape(values)[0]
                    density = non_zero_count / tf.cast(total_elements, tf.float32)
                    return density.numpy()
                
                # è¨ˆç®—è¨»é‡‹å¯†åº¦
                notes_density = parse_sparse_tensor(
                    example['notes_values'],
                    example['notes_indices'],
                    example['notes_onsets_shape']
                )
                onsets_density = parse_sparse_tensor(
                    example['onsets_values'],
                    example['onsets_indices'],
                    example['notes_onsets_shape']
                )
                contours_density = parse_sparse_tensor(
                    example['contours_values'],
                    example['contours_indices'],
                    example['contours_shape']
                )
                
                all_stats['notes_density'].append(notes_density)
                all_stats['onsets_density'].append(onsets_density)
                all_stats['contours_density'].append(contours_density)
                
                print(f"     notes å¯†åº¦: {notes_density:.4%}")
                print(f"     onsets å¯†åº¦: {onsets_density:.4%}")
                print(f"     contours å¯†åº¦: {contours_density:.4%}")
        
        # çµ±è¨ˆä¿¡æ¯
        print("\nğŸ“Š ç¸½é«”çµ±è¨ˆ:")
        print(f"   å¹³å‡éŸ³é »é•·åº¦: {np.mean(all_stats['audio_lengths']):.0f} æ¡æ¨£é»")
        print(f"   å¹³å‡ notes å¯†åº¦: {np.mean(all_stats['notes_density']):.4%}")
        print(f"   å¹³å‡ onsets å¯†åº¦: {np.mean(all_stats['onsets_density']):.4%}")
        print(f"   å¹³å‡ contours å¯†åº¦: {np.mean(all_stats['contours_density']):.4%}")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ•¸æ“šå•é¡Œ
        if np.mean(all_stats['notes_density']) < 0.001:
            print("\nâš ï¸  è­¦å‘Š: notes å¯†åº¦éå¸¸ä½ï¼Œå¯èƒ½æ•¸æ“šæœ‰å•é¡Œ")
        if np.mean(all_stats['onsets_density']) < 0.001:
            print("âš ï¸  è­¦å‘Š: onsets å¯†åº¦éå¸¸ä½ï¼Œå¯èƒ½æ•¸æ“šæœ‰å•é¡Œ")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    print("é–‹å§‹æ¸¬è©¦ TFRecord æ•¸æ“šæ ¼å¼...")
    
    # æ¸¬è©¦å–®å€‹æ¨£æœ¬
    success1 = test_official_parser()
    
    if success1:
        # æ¸¬è©¦å¤šå€‹æ¨£æœ¬
        test_multiple_samples()
        
        print("\nâœ… æ¸¬è©¦å®Œæˆï¼")
        print("\nğŸ¯ ä¸‹ä¸€æ­¥:")
        print("1. å¦‚æœæ•¸æ“šçœ‹èµ·ä¾†æ­£å¸¸ï¼Œå¯ä»¥ç¹¼çºŒè¨“ç·´")
        print("2. å¦‚æœè¨»é‡‹å¯†åº¦å¤ªä½ï¼Œå¯èƒ½éœ€è¦æª¢æŸ¥æ•¸æ“šç”Ÿæˆéç¨‹")
        print("3. ä½¿ç”¨ä¿®æ­£çš„å¾®èª¿è…³æœ¬é–‹å§‹è¨“ç·´")