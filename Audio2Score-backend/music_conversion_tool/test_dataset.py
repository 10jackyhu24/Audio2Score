# test_dataset.py
import tensorflow as tf
import numpy as np
import os

def test_tfrecord_data(tfrecord_dir):
    """æ¸¬è©¦TFRecordæ•¸æ“š"""
    
    print("=== TFRecordæ•¸æ“šæ¸¬è©¦ ===")
    
    if not os.path.exists(tfrecord_dir):
        print(f"âŒ ç›®éŒ„ä¸å­˜åœ¨: {tfrecord_dir}")
        return
    
    # æŸ¥æ‰¾TFRecordæ–‡ä»¶
    tfrecord_files = []
    for root, dirs, files in os.walk(tfrecord_dir):
        for file in files:
            if file.endswith('.tfrecord') or file.endswith('.tfrecords'):
                tfrecord_files.append(os.path.join(root, file))
    
    print(f"æ‰¾åˆ° {len(tfrecord_files)} å€‹TFRecordæ–‡ä»¶")
    
    if not tfrecord_files:
        print("âŒ æ²’æœ‰æ‰¾åˆ°TFRecordæ–‡ä»¶")
        return
    
    # æ¸¬è©¦ç¬¬ä¸€å€‹æ–‡ä»¶
    test_file = tfrecord_files[0]
    print(f"\næ¸¬è©¦æ–‡ä»¶: {test_file}")
    
    # å‰µå»ºæ•¸æ“šé›†
    raw_dataset = tf.data.TFRecordDataset(test_file)
    
    # å®šç¾©è§£æå‡½æ•¸ï¼ˆæ ¹æ“šBasic Pitchçš„æ ¼å¼ï¼‰
    feature_description = {
        'audio': tf.io.FixedLenFeature([], tf.string),
        'contours': tf.io.FixedLenFeature([], tf.string),
        'notes': tf.io.FixedLenFeature([], tf.string),
        'onsets': tf.io.FixedLenFeature([], tf.string),
    }
    
    def parse_example(example_proto):
        parsed = tf.io.parse_single_example(example_proto, feature_description)
        
        # è§£æéŸ³é »
        audio = tf.io.parse_tensor(parsed['audio'], out_type=tf.float32)
        audio = tf.reshape(audio, [43844, 1])
        
        # è§£ææ¨™ç±¤
        contours = tf.io.parse_tensor(parsed['contours'], out_type=tf.float32)
        notes = tf.io.parse_tensor(parsed['notes'], out_type=tf.float32)
        onsets = tf.io.parse_tensor(parsed['onsets'], out_type=tf.float32)
        
        return audio, {'contour': contours, 'note': notes, 'onset': onsets}
    
    dataset = raw_dataset.map(parse_example)
    
    # æª¢æŸ¥å¹¾å€‹æ¨£æœ¬
    print("\næª¢æŸ¥æ•¸æ“šæ¨£æœ¬:")
    count = 0
    for audio, labels in dataset.take(3):
        print(f"\næ¨£æœ¬ {count + 1}:")
        print(f"  éŸ³é »å½¢ç‹€: {audio.shape}, ç¯„åœ: [{audio.numpy().min():.3f}, {audio.numpy().max():.3f}]")
        
        for label_name, label in labels.items():
            label_np = label.numpy()
            print(f"  {label_name}: å½¢ç‹€ {label.shape}, "
                  f"éé›¶æ¯”ä¾‹: {np.mean(label_np > 0):.2%}, "
                  f"ç¯„åœ: [{label_np.min():.3f}, {label_np.max():.3f}]")
        
        count += 1
    
    # çµ±è¨ˆä¿¡æ¯
    print(f"\nğŸ“Š æ•¸æ“šçµ±è¨ˆ:")
    total_samples = 0
    audio_stats = []
    label_stats = {'contour': [], 'note': [], 'onset': []}
    
    for audio, labels in dataset.take(100):  # æª¢æŸ¥å‰100å€‹
        total_samples += 1
        audio_stats.append(audio.numpy())
        
        for label_name, label in labels.items():
            label_stats[label_name].append(label.numpy())
    
    print(f"   æª¢æŸ¥äº† {total_samples} å€‹æ¨£æœ¬")
    
    if audio_stats:
        all_audio = np.concatenate([a.flatten() for a in audio_stats])
        print(f"   éŸ³é » - å¹³å‡å€¼: {all_audio.mean():.6f}, æ¨™æº–å·®: {all_audio.std():.6f}")
    
    for label_name, stats in label_stats.items():
        if stats:
            all_labels = np.concatenate([s.flatten() for s in stats])
            pos_ratio = np.mean(all_labels > 0.5)  # é–¾å€¼0.5
            print(f"   {label_name} - æ­£æ¨£æœ¬æ¯”ä¾‹: {pos_ratio:.2%}, "
                  f"å¹³å‡å€¼: {all_labels.mean():.6f}")

if __name__ == "__main__":
    test_tfrecord_data("./output_tfrecord")